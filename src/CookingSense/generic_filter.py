from spacy.tokens import Span, Token
from typing import Union

"""
core function : is_generic

Input  List<DocBin>     : Sentences
Output List<Boolean>    : Boolean results whether this sentence is generic or not  
Usage  : df['generic'] = df['sen_span'].apply(is_generic)
"""



def get_first_word(sentence: Span) -> Union[None, Token]:
    """
    Returns the first word of a sentence, ignoring the heading spaces
    """
    if len(sentence) == 0:
        return None

    first_word = sentence[0]
    i = 0
    while first_word.is_space:
        if i >= len(sentence):
        # if i > len(sentence):
            return None

        try:
            first_word = sentence[i + 1]
        except BaseException as e:
            # print(e, '\t', sentence, '\t', i)
            return None
        i += 1
    return first_word


def get_doc_url(sentence: Span) -> str:
    """
    Returns the URL of the document containing the sentence, if it exists,
    otherwise returns an empty string
    """
    return sentence.doc.user_data.get("url", "")

_filter_config = {
    "is-short-enough": {
        "max_length": 150
    },
    "has-no-bad-first-word":{
        "words":[
            "this","that","these","those","he","she","her","his"
        ]
    },
    "all-propn-have-acceptable-ne-labels":{
        "excluded": []
    },
    "has-no-pronouns":{
        "words":[ "i", "me", "my", "we", "us", "our", "you", "your"]
    },
    "not-from-unreliable-source":{
        "domain_tails": ["tk"]
    }
}

filter = {
            "is-short-enough": (
                lambda s: len(s.text.strip()) <=
                          _filter_config["is-short-enough"]["max_length"]),
            "has-at-least-one-token": (lambda s: len(s) >= 1),
            "first-word-is-not-none": (
                lambda s: get_first_word(s) is not None and get_first_word(
                    s).text.strip() != ""),
            "starts-with-capital": (
                lambda s: get_first_word(s).text[0].isupper()),
            "ends-with-period": (lambda s: s.text.strip()[-1] == "."),
            "has-no-bad-first-word": (
                lambda s: get_first_word(s).lower_ not in
                          _filter_config["has-no-bad-first-word"][
                              "words"]),
            "first-word-is-not-verb": (
                lambda s: get_first_word(s).pos_ != "VERB"),
            "first-word-is-not-conjunction": (
                lambda s: get_first_word(s).pos_ not in {"CCONJ", "SCONJ"}),
            "noun-exists-before-root": (lambda s: any(
                t.pos_ in {"NOUN", "PROPN"} for t in s if t.i < s.root.i)),
            "has-no-digits": (lambda s: not any(t.isdigit() for t in s.text)),

            "all-propn-have-acceptable-ne-labels": (lambda s: all(
                e.label_ not in set(_filter_config[
                    "all-propn-have-acceptable-ne-labels"].get(
                    "excluded", [])) for e in s.ents)),

            "has-no-pronouns": (lambda s: not any((t.lower_ in set(
                _filter_config["has-no-pronouns"][
                    "words"])) and t.pos_ == "PRON" for t in s)),

            "root-has-nsubj-or-nsubjpass": (
                lambda s: any(
                    t.dep_ in {"nsubj", "nsubjpass"} for t in s.root.children)),

            "has-no-email": (lambda s: not any(t.like_email for t in s)),
            "scr.dot_dot_in_sentence": (lambda s: ".." not in s.text),
            "scr.www_in_sentence": (lambda s: "www" not in s.text),
            "scr.com_in_sentence": (lambda s: "com" not in s.text),
            "scr.http_in_sentence": (lambda s: "http" not in s.text),

            "scr.many_hyphens_in_sentence": (
                lambda s: s.text.count("-") < 2 and s.text.count("â€“") < 2),
            # these are two different hyphens

            "remove-non-verb-roots": (lambda s: s.root.pos_ in {"VERB", "AUX"}),
            "remove-first-word-roots": (
                lambda s: s.root.i != get_first_word(s).i),

            "remove-present-participle-roots": (lambda s: s.root.tag_ != "VBG"),
            "remove-past-tense-roots": (lambda s: s.root.tag_ != "VBD"),

            "not-from-unreliable-source": (
                lambda s: not any(f".{d}/" in get_doc_url(s) for d in
                                  _filter_config[
                                      "not-from-unreliable-source"][
                                      "domain_tails"])),
        }

def is_generic( s: Span) -> bool:
    if len(s) ==0:
        return None
    return not any((not func(s)) for func in filter.values())
